## foolproofNN
A project for  investigating Adversarial Examples in NNs and their existence. 
Implemented with PyTorch.

Datasets:
- [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)

Implementations:
- [N. Carlini and D. Wagner, "Towards Evaluating the Robustness of Neural Networks," 2017 IEEE Symposium on Security and Privacy (SP), 2017, pp. 39-57, doi: 10.1109/SP.2017.49.](https://ieeexplore.ieee.org/document/7958570)
